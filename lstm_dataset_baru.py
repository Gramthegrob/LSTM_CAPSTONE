# -*- coding: utf-8 -*-
"""LSTM DATASET BARU

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/113r5OcTqo6g-aub2mP4QjxAlRfdwAntm
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/drive/MyDrive/Dataset/Improved_All_Combined_hr_rsp_binary.csv')
print ("Jumlah NaN")
print (df.isna().sum())

df_clean = df.dropna()
print ("jumlah NaN")
print (df_clean.isna().sum())

features = df_clean[["HR", "respr"]].values  # hanya 2 fitur tersedia
labels = df_clean["Label"].values

# Normalisasi fitur
scaler = MinMaxScaler()
features_scaled = scaler.fit_transform(features)

# Buat window time-series (128 timestep)
def create_sequences(features, labels, window_size=128):
    X, y = [], []
    for i in range(len(features) - window_size):
        X.append(features[i:i+window_size])
        y.append(labels[i+window_size])
    return np.array(X), np.array(y)

X, y = create_sequences(features_scaled, labels, window_size=128)

# One-hot encode label karena output pakai softmax
y = to_categorical(y, num_classes=2)

# Split data: 70% train, 10% val, 20% test
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.30, stratify=y.argmax(axis=1), random_state=42)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=1/3, stratify=y_temp.argmax(axis=1), random_state=42)

model = Sequential([
    LSTM(100, return_sequences=True, input_shape=(128, 2)),
    Dropout(0.1),
    LSTM(100),
    Dense(100, activation='relu'),
    Dense(2, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Callback untuk early stopping
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Latih model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,
    batch_size=64,
    callbacks=[early_stop],
    verbose=1
)

# Prediksi
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Evaluasi
print(classification_report(y_true_classes, y_pred_classes))

# Callback untuk early stopping
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Latih model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=30,                    # dinaikkan agar lebih fleksibel
    batch_size=64,
    callbacks=[early_stop],
    verbose=1
)

# Prediksi
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Evaluasi
print(classification_report(y_true_classes, y_pred_classes))

def plot_confusion_matrix(y_true, y_pred, labels=['Not Stressed', 'Stressed']):
    cm = confusion_matrix(y_true, y_pred)

    # Ekstrak nilai TN, FP, FN, TP
    tn, fp, fn, tp = cm.ravel()

    # Label untuk setiap sel
    labels_text = np.array([
        [f"TN = {tn}", f"FP = {fp}"],
        [f"FN = {fn}", f"TP = {tp}"]
    ])

    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=labels_text, fmt='', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.title("Confusion Matrix with Labels")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()